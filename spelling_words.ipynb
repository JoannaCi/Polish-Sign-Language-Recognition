{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 1,\n",
       " '<eos>': 2,\n",
       " 'j': 3,\n",
       " 'r': 4,\n",
       " 'z': 5,\n",
       " 't': 6,\n",
       " 's': 7,\n",
       " 'n': 8,\n",
       " 'g': 9,\n",
       " 'b': 10,\n",
       " 'l': 11,\n",
       " 'y': 12,\n",
       " 'ch': 13,\n",
       " 'u': 14,\n",
       " 'ó': 15,\n",
       " 'd': 16,\n",
       " 'f': 17,\n",
       " 'ż': 18,\n",
       " 'k': 19,\n",
       " 'e': 20,\n",
       " 'cz': 21,\n",
       " 'sz': 22,\n",
       " 'o': 23,\n",
       " 'ź': 24,\n",
       " 'm': 25,\n",
       " 'ń': 26,\n",
       " 'ć': 27,\n",
       " 'c': 28,\n",
       " 'i': 29,\n",
       " 'ł': 30,\n",
       " 'ą': 31,\n",
       " 'w': 32,\n",
       " 'h': 33,\n",
       " 'ś': 34,\n",
       " 'rz': 35,\n",
       " 'a': 36,\n",
       " 'p': 37}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = [l.split('.')[0].lower() for l in os.listdir(\"/home/ant/projects/psl/dataset/Videos/alphabet\")]\n",
    "vocabulary = ['<start>', '<eos>'] + letters\n",
    "vocabulary = {l: i+1 for i, l in enumerate(vocabulary)}\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1705528967.587493    3400 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705528967.608517    4398 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.146.02), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n"
     ]
    }
   ],
   "source": [
    "def landmarks_timeseries(video_path):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_rate = 0.5\n",
    "    frames_to_skip = int(fps * frame_rate)\n",
    "    landmarks_data = []\n",
    "    current_frame = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Set the position to the current frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame and get landmarks\n",
    "        results = hands.process(rgb_frame)\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0].landmark\n",
    "            landmarks_data.append([[landmark.x, landmark.y, landmark.z] for landmark in hand_landmarks])\n",
    "\n",
    "        current_frame += frames_to_skip\n",
    "\n",
    "    cap.release()\n",
    "    landmarks_data = np.array(landmarks_data).reshape(len(landmarks_data), -1)\n",
    "    return landmarks_data\n",
    "\n",
    "\n",
    "\n",
    "video_path = \"/home/ant/projects/psl/dataset/Videos/alphabet/C.mp4\"\n",
    "lands = landmarks_timeseries(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 63)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?it/s]I0000 00:00:1705528968.474072    3400 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705528968.480680    4415 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.146.02), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/35 [00:00<00:22,  1.51it/s]I0000 00:00:1705528969.135125    3400 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705528969.141603    4432 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.146.02), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n",
      "  6%|▌         | 2/35 [00:01<00:23,  1.42it/s]I0000 00:00:1705528969.873171    3400 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705528969.879696    4449 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.146.02), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n",
      "  9%|▊         | 3/35 [00:02<00:26,  1.22it/s]I0000 00:00:1705528970.822064    3400 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705528970.828664    4466 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.146.02), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n",
      "  9%|▊         | 3/35 [00:03<00:33,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "videos_path = \"/home/ant/projects/psl/dataset/Videos/alphabet\"\n",
    "labels = []\n",
    "landmarks = []\n",
    "for i, filename in enumerate(tqdm(os.listdir(videos_path))):\n",
    "    if filename.endswith('.mp4'):\n",
    "        video_path = os.path.join(videos_path, filename)\n",
    "        # print(video_path)\n",
    "        label = filename.split('.')[0].lower()\n",
    "        label = ['<start>', label, '<eos>']\n",
    "        label = [vocabulary[l] for l in label]\n",
    "        labels.append(label)\n",
    "        land = landmarks_timeseries(video_path)\n",
    "        landmarks.append(land)\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1705528971.617498    3400 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705528971.624636    4483 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.146.02), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n",
      "  0%|          | 1/375 [00:01<06:15,  1.00s/it]I0000 00:00:1705528972.621395    3400 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705528972.628031    4500 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.146.02), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n",
      "  1%|          | 2/375 [00:03<10:04,  1.62s/it]I0000 00:00:1705528974.673917    3400 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705528974.680550    4517 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.146.02), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n",
      "  1%|          | 3/375 [00:06<14:06,  2.28s/it]I0000 00:00:1705528977.727850    3400 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705528977.734595    4534 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.146.02), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n",
      "  1%|          | 3/375 [00:07<15:29,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "videos_path = \"/home/ant/projects/psl/dataset/Videos/words\"\n",
    "labels_words = []\n",
    "landmarks_words = []\n",
    "for i, filename in enumerate(tqdm(os.listdir(videos_path))):\n",
    "    if filename.endswith('.mp4'):\n",
    "        video_path = os.path.join(videos_path, filename)\n",
    "        # print(video_path)\n",
    "        label = ['<start>'] + list(filename.split('.')[0].lower()) + ['<eos>']\n",
    "        label = [vocabulary[l] for l in label]\n",
    "        labels_words.append(label)\n",
    "        land = landmarks_timeseries(video_path)\n",
    "        landmarks_words.append(land)\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 36, 11, 36, 2],\n",
       " [1, 5, 12, 7, 19, 2],\n",
       " [1, 4, 23, 5, 16, 5, 29, 36, 30, 2],\n",
       " [1, 28, 20, 11, 2]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 63)\n",
      "(12, 63)\n",
      "(22, 63)\n",
      "(9, 63)\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(landmarks_words):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(labels_folder):\n",
    "    labeled_with_landmarks_count = 0\n",
    "    labeled_without_landmarks_count = 0\n",
    "    data_rows = []\n",
    "    labels = []\n",
    "    fix = {\n",
    "        'Ć': 'ć',\n",
    "        'P': 'E',\n",
    "        'SZ': 'B',\n",
    "        'Ę': 'ę',\n",
    "        'CH': 'H',\n",
    "        'I': 'J',\n",
    "        'Ł': 'ł',\n",
    "        'Ń': 'ń',\n",
    "        'Ó': 'O',\n",
    "        'RZ': 'R',\n",
    "        'Ś': 'ś',\n",
    "        'Ź': 'ź',\n",
    "        'Ż': 'ż',\n",
    "    }\n",
    "\n",
    "    for filename in tqdm(os.listdir(labels_folder)):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(labels_folder, filename), 'r', encoding='utf-8') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                if 'hand_landmarks' in data:\n",
    "                    labeled_with_landmarks_count += 1\n",
    "\n",
    "                    landmarks_data = data['hand_landmarks']\n",
    "                    row = []\n",
    "                    \n",
    "                    for landmark_key in landmarks_data:\n",
    "                        landmark = landmarks_data[landmark_key]\n",
    "                        row.extend([landmark['x'], landmark['y'], landmark['z']])\n",
    "                    \n",
    "                    \n",
    "                    l = data['label']\n",
    "                    if l in fix:\n",
    "                        l = fix[l] \n",
    "                    label = ['<start>', l.lower(), '<eos>']\n",
    "                    try:\n",
    "                        label = [vocabulary[l] for l in label]\n",
    "                    except: # skip for ę, fix later\n",
    "                        continue\n",
    "                    data_rows.append(row)\n",
    "                    labels.append(label)\n",
    "\n",
    "                else:\n",
    "                    labeled_without_landmarks_count += 1\n",
    "\n",
    "    return data_rows, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3626/3626 [00:00<00:00, 17702.22it/s]\n"
     ]
    }
   ],
   "source": [
    "labels_folder = '../dataset/labels'\n",
    "data_static, labels_static = preprocess_data(labels_folder)\n",
    "data_static = np.array(data_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_static_new = []\n",
    "for d in data_static:\n",
    "    d = np.repeat(d.reshape(1, -1), repeats=np.random.randint(2, 7), axis=0)\n",
    "    data_static_new.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = landmarks + landmarks_words + data_static_new \n",
    "all_labels = labels + labels_words + labels_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "  def __init__(self):\n",
    "    self.name = 'masked_loss'\n",
    "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "\n",
    "  def __call__(self, y_true, y_pred, *args, **kwargs):\n",
    "\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss = self.loss(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_inputs = tf.keras.utils.pad_sequences(data, dtype=\"float32\", padding=\"post\")\n",
    "padded_outputs = tf.keras.utils.pad_sequences(all_labels, dtype=\"int32\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_19 (Masking)        (None, 22, 63)            0         \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 32)                12288     \n",
      "                                                                 \n",
      " repeat_vector_10 (RepeatVec  (None, 10, 32)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 10, 64)            24832     \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 10, 37)           2405      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,525\n",
      "Trainable params: 39,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "input_dim = 63\n",
    "vocab_size = len(vocabulary)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(padded_inputs.shape[1], input_dim), dtype=\"float32\"),\n",
    "        keras.layers.Masking(),\n",
    "        keras.layers.LSTM(32, return_sequences=False),\n",
    "        keras.layers.RepeatVector(padded_outputs.shape[1]),\n",
    "        keras.layers.LSTM(64, return_sequences=True),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(vocab_size)),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# tf.keras.losses.sparse_categorical_crossentropy\n",
    "model.compile(loss=masked_loss,\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3181, 22, 63), (3181, 10))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inputs.shape, padded_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 22:10:14.916870: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_40/output/_23'\n",
      "2024-01-17 22:10:15.076903: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2bf7b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-17 22:10:15.076926: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 970, Compute Capability 5.2\n",
      "2024-01-17 22:10:15.079697: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-17 22:10:15.091582: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:56] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.2\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2024-01-17 22:10:15.092430: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2024-01-17 22:10:15.092543: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-01-17 22:10:15.092603: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2024-01-17 22:10:15.105100: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2024-01-17 22:10:15.105254: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n      app.start()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n      result = self._run_cell(\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n      result = runner(coro)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3400/283080546.py\", line 1, in <module>\n      model.fit(padded_inputs, padded_outputs)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_6'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_6}}]] [Op:__inference_train_function_55905]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/psl/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/psl/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n      app.start()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n      result = self._run_cell(\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n      result = runner(coro)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3400/283080546.py\", line 1, in <module>\n      model.fit(padded_inputs, padded_outputs)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_6'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_6}}]] [Op:__inference_train_function_55905]"
     ]
    }
   ],
   "source": [
    "model.fit(padded_inputs, padded_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([-0.00617623,  0.07038333, -0.09975268,  0.04994547, -0.08556576,\n",
       "       -0.01439674,  0.00178766,  0.12056605,  0.0055276 , -0.00410856,\n",
       "        0.04292813,  0.01083074, -0.00749248, -0.02138753, -0.07583385,\n",
       "       -0.00663034, -0.13346957,  0.08411147,  0.00640909,  0.02036927,\n",
       "        0.06142245, -0.01554792,  0.04529171, -0.0598767 ,  0.02836076,\n",
       "        0.08498958,  0.03581278, -0.08666255,  0.0232823 , -0.06233657,\n",
       "        0.03195114,  0.04139042, -0.06258518,  0.19337499,  0.0564622 ,\n",
       "       -0.0120612 , -0.06972692, -0.1224641 , -0.11664062, -0.0519244 ,\n",
       "        0.0722313 ,  0.09256959, -0.06957745, -0.02159714, -0.10800963,\n",
       "        0.09039993,  0.05151774,  0.06304382,  0.14077818, -0.07688762,\n",
       "        0.02922654, -0.06657206, -0.03469027, -0.02914091, -0.01539665,\n",
       "       -0.01945005, -0.03742137,  0.00620591, -0.02648269,  0.11653467,\n",
       "        0.01066596, -0.2610688 , -0.04025134,  0.09088983], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(padded_inputs[:2])[0][4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
