{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import unicodedata\n",
    "import uuid\n",
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_folder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        shutil.rmtree(path)           # Removes all the subdirectories!\n",
    "        print('Directory existed and was cleaned')\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_raw = '../dataset/images_raw'\n",
    "folder_path = '../dataset/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory existed and was cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3741 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3741/3741 [02:11<00:00, 28.36it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_to_jpg(file_path, path_to_save):\n",
    "    img = Image.open(file_path)\n",
    "    if img.format == 'PNG': # Conversion of png to jpg\n",
    "        file_name = os.path.splitext(path_to_save)[0]\n",
    "        img = img.convert(\"RGB\")\n",
    "        img.save(file_name + '.jpg', 'JPEG')\n",
    "    else:\n",
    "        file_name = os.path.splitext(path_to_save)[0]\n",
    "        img.save(file_name + '.jpg', 'JPEG')\n",
    "\n",
    "create_new_folder(folder_path)\n",
    "\n",
    "for file_name in tqdm(os.listdir(folder_path_raw)):\n",
    "    if file_name.lower().endswith('.png') or  file_name.lower().endswith('.jpg'):\n",
    "        file_path = os.path.join(folder_path_raw, file_name)\n",
    "        path_to_save = os.path.join(folder_path, file_name)\n",
    "        convert_to_jpg(file_path, path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3702\n"
     ]
    }
   ],
   "source": [
    "with os.scandir(folder_path) as entries: # Used scandir instead of listdir to detect Polish characters (e.g ą,ę)\n",
    "    print(len(list(entries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory existed and was cleaned\n",
      "Directory existed and was cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "3702it [02:17, 26.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3626 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(folder_path):\n",
    "    labels = {}\n",
    "    \n",
    "    skipped = 0\n",
    "    created = 0\n",
    "    labels_folder = '../dataset/labels/'\n",
    "    images_path = '../dataset/images_renamed'\n",
    "    \n",
    "    create_new_folder(labels_folder)\n",
    "    create_new_folder(images_path)\n",
    "\n",
    "    # Initialize MediaPipe Hands\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # Searching for files in a folder\n",
    "    with os.scandir(folder_path) as entries: # Used scandir instead of listdir to detect Polish characters (e.g ą,ę)\n",
    "        for entry in tqdm(entries):\n",
    "            if entry.is_file() and entry.name.lower().endswith('.jpg'): # I want to exclude files that are not jpg\n",
    "                filename = entry.name\n",
    "                #print(filename)\n",
    "                label = ''.join([c for c in filename.split('.')[0] if not c.isdigit()])\n",
    "                \n",
    "                # Skip file names starting with 'img'\n",
    "                if filename.lower().startswith('img'):\n",
    "                    # print(f'skipping starting with img {filename}')\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                \n",
    "                # Normalize the filename to ensure proper handling of diacritical marks\n",
    "                normalized_filename = unicodedata.normalize('NFC', filename)\n",
    "\n",
    "                # Check if filename contains 'sz', 'cz', 'ch' or 'rz'\n",
    "                if 'sz' in filename:\n",
    "                    labels[filename] = 'sz'\n",
    "                elif 'cz' in filename:\n",
    "                    labels[filename] = 'cz'\n",
    "                elif 'ch' in filename:\n",
    "                    labels[filename] = 'ch'\n",
    "                elif 'rz' in filename:\n",
    "                    labels[filename] = 'rz'\n",
    "                else:    \n",
    "                    # Retrieving the first letter of the file name    \n",
    "                    labels[normalized_filename] = label\n",
    "                \n",
    "                # Prepare the label dictionary for the current image\n",
    "                image_labels = {'label': label}\n",
    "                \n",
    "                new_file_name = str(uuid.uuid4()).replace('-', '')\n",
    "                shutil.copyfile(os.path.join(folder_path, filename), os.path.join(images_path, new_file_name + '.jpg'))\n",
    "\n",
    "                # Process image using MediaPipe: loading image\n",
    "                image = cv2.imread(os.path.join(folder_path, filename))  # Loading the image from disk\n",
    "                # Convert the image to RGB format (MediaPipe requires RGB input)\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # Processing the image using MediaPipe Hands\n",
    "                results = hands.process(image_rgb)\n",
    "\n",
    "                # Get landmarks and add them to the label dictionary\n",
    "                if results.multi_hand_landmarks:  # Checking if hand landmarks exist in the image processing results\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        landmarks = hand_landmarks.landmark  # Retrieving the hand landmarks\n",
    "                        \n",
    "                        # Creating a dictionary containing the coordinates of the hand landmarks\n",
    "                        landmark_dict = {f'hand_landmark_{i}': {'x': landmark.x, 'y': landmark.y, 'z': landmark.z} for i, landmark in enumerate(landmarks)}\n",
    "                        image_labels['hand_landmarks'] = landmark_dict  # Adding the hand landmarks to the label dictionary for the image\n",
    "                \n",
    "               # Saving the results to a JSON file\n",
    "                with open(os.path.join(labels_folder, f'{new_file_name}.json'), 'w', encoding='utf-8') as json_file:\n",
    "                    json.dump(image_labels, json_file,  indent=4, ensure_ascii=False)\n",
    "                created += 1\n",
    "            else:\n",
    "                skipped += 1  \n",
    "    print(created, skipped)\n",
    "\n",
    "# Calling the function\n",
    "extract_labels(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_with_landmarks(labels_folder):\n",
    "    labeled_with_landmarks_count = 0\n",
    "    labeled_without_landmarks_count = 0\n",
    "    data_rows = []\n",
    "    # Iterate through files in the labels folder\n",
    "    for filename in tqdm(os.listdir(labels_folder)):\n",
    "        if filename.endswith('.json'):  # Check if the file is a JSON file\n",
    "            with open(os.path.join(labels_folder, filename), 'r', encoding='utf-8') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                # Check if the JSON file contains the 'landmarks' section\n",
    "                if 'hand_landmarks' in data:\n",
    "                    labeled_with_landmarks_count += 1\n",
    "\n",
    "                    # Inspect the structure of 'hand_landmarks'\n",
    "                    landmarks_data = data['hand_landmarks']\n",
    "                    # print(landmarks_data)  # Print or inspect the structure\n",
    "                        \n",
    "                    # Initialisation of the line for each characteristic point\n",
    "                    row = []\n",
    "                    \n",
    "                    # Adding x, y, z coordinates of each point to the row\n",
    "                    for landmark_key in landmarks_data:\n",
    "                        landmark = landmarks_data[landmark_key]\n",
    "                        row.extend([landmark['x'], landmark['y'], landmark['z']])\n",
    "                    \n",
    "                    # Adding a label at the end of the line\n",
    "                    row.append(data['label'])  # Use the label as a label\n",
    "                    \n",
    "                    # Adding a row to the data list\n",
    "                    data_rows.append(row)\n",
    "\n",
    "                    # print(data_rows[0])  # Display of the first line for the example\n",
    "\n",
    "                else:\n",
    "                    labeled_without_landmarks_count += 1\n",
    "    print(data_rows[0])\n",
    "    print(len(data_rows[0]))\n",
    "    return labeled_with_landmarks_count, labeled_without_landmarks_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3626/3626 [00:00<00:00, 21990.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4068658649921417, 0.8311142921447754, 3.596598787680705e-07, 0.5548468232154846, 0.7648515701293945, -0.019808441400527954, 0.6082077026367188, 0.6337907314300537, -0.027444979175925255, 0.627790629863739, 0.5394436717033386, -0.041216425597667694, 0.6606267690658569, 0.46657809615135193, -0.058081209659576416, 0.5870953798294067, 0.48167476058006287, -0.012021823786199093, 0.5937815308570862, 0.35036206245422363, -0.06346968561410904, 0.6154494881629944, 0.26099270582199097, -0.10753510147333145, 0.6353161931037903, 0.1836731731891632, -0.14013127982616425, 0.5398607850074768, 0.4878859221935272, -0.04159051924943924, 0.5540778636932373, 0.3466029167175293, -0.09158556908369064, 0.5805823802947998, 0.2500249147415161, -0.13458271324634552, 0.6048976182937622, 0.1618865430355072, -0.1652085781097412, 0.49128201603889465, 0.5162795186042786, -0.07832977175712585, 0.5050534009933472, 0.37745168805122375, -0.13170874118804932, 0.5279346704483032, 0.28414350748062134, -0.16351939737796783, 0.5493180751800537, 0.19995924830436707, -0.1834065020084381, 0.43988117575645447, 0.5643997192382812, -0.11818202584981918, 0.4540652632713318, 0.45710766315460205, -0.1663808971643448, 0.4805986285209656, 0.38366565108299255, -0.18743541836738586, 0.5100936889648438, 0.3175644874572754, -0.20091697573661804, 'SZ']\n",
      "64\n",
      "Number of JSON files with landmarks information: 3262\n",
      "Number of JSON files without landmarks information: 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels_path= '../dataset/labels'\n",
    "number_of_labeled_files_with_landmarks, number_of_labeled_files_without_landmarks = count_files_with_landmarks(labels_path)\n",
    "print(f'Number of JSON files with landmarks information: {number_of_labeled_files_with_landmarks}')\n",
    "print(f'Number of JSON files without landmarks information: {number_of_labeled_files_without_landmarks}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
