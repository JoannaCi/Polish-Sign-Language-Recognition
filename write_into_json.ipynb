{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import unicodedata\n",
    "import uuid\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_folder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        shutil.rmtree(path)           # Removes all the subdirectories!\n",
    "        print('Directory existed and was cleaned')\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_raw = '../dataset/images_raw'\n",
    "folder_path = '../dataset/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory existed and was cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3741/3741 [02:10<00:00, 28.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_to_jpg(file_path, path_to_save):\n",
    "    img = Image.open(file_path)\n",
    "    if img.format == 'PNG': # Conversion of png to jpg\n",
    "        file_name = os.path.splitext(path_to_save)[0]\n",
    "        img = img.convert(\"RGB\")\n",
    "        img.save(file_name + '.jpg', 'JPEG')\n",
    "    else:\n",
    "        file_name = os.path.splitext(path_to_save)[0]\n",
    "        img.save(file_name + '.jpg', 'JPEG')\n",
    "\n",
    "create_new_folder(folder_path)\n",
    "\n",
    "for file_name in tqdm(os.listdir(folder_path_raw)):\n",
    "    if file_name.lower().endswith('.png') or  file_name.lower().endswith('.jpg'):\n",
    "        file_path = os.path.join(folder_path_raw, file_name)\n",
    "        path_to_save = os.path.join(folder_path, file_name)\n",
    "        convert_to_jpg(file_path, path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3702\n"
     ]
    }
   ],
   "source": [
    "with os.scandir(folder_path) as entries: # Used scandir instead of listdir to detect Polish characters (e.g ą,ę)\n",
    "    print(len(list(entries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1704367923.163823   85283 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1704367923.180162   85453 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.129.03), renderer: NVIDIA GeForce GTX 970/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory existed and was cleaned\n",
      "Directory existed and was cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "3702it [02:19, 26.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3626 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(folder_path):\n",
    "    labels = {}\n",
    "    # /home/ant/projects/psl/dataset/images/A35.jpg\n",
    "    skipped = 0\n",
    "    created = 0\n",
    "    labels_folder = '../dataset/labels/'\n",
    "    images_path = '../dataset/images_renamed'\n",
    "    \n",
    "    create_new_folder(labels_folder)\n",
    "    create_new_folder(images_path)\n",
    "\n",
    "    # Initialize MediaPipe Hands\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # Searching for files in a folder\n",
    "    with os.scandir(folder_path) as entries: # Used scandir instead of listdir to detect Polish characters (e.g ą,ę)\n",
    "        for entry in tqdm(entries):\n",
    "            if entry.is_file() and entry.name.lower().endswith('.jpg'): # I want to exclude files that are not jpg\n",
    "                filename = entry.name\n",
    "                #print(filename)\n",
    "                label = ''.join([c for c in filename.split('.')[0] if not c.isdigit()])\n",
    "                \n",
    "                # Skip file names starting with 'img'\n",
    "                if filename.lower().startswith('img'):\n",
    "                    # print(f'skipping starting with img {filename}')\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                \n",
    "                # Normalize the filename to ensure proper handling of diacritical marks\n",
    "                normalized_filename = unicodedata.normalize('NFC', filename)\n",
    "\n",
    "                # Check if filename contains 'sz', 'cz', 'ch' or 'rz'\n",
    "                if 'sz' in filename:\n",
    "                    labels[filename] = 'sz'\n",
    "                elif 'cz' in filename:\n",
    "                    labels[filename] = 'cz'\n",
    "                elif 'ch' in filename:\n",
    "                    labels[filename] = 'ch'\n",
    "                elif 'rz' in filename:\n",
    "                    labels[filename] = 'rz'\n",
    "                else:    \n",
    "                    # Retrieving the first letter of the file name    \n",
    "                    labels[normalized_filename] = label\n",
    "                \n",
    "                # Prepare the label dictionary for the current image\n",
    "                image_labels = {'label': label}\n",
    "                \n",
    "                new_file_name = str(uuid.uuid4()).replace('-', '')\n",
    "                shutil.copyfile(os.path.join(folder_path, filename), os.path.join(images_path, new_file_name + '.jpg'))\n",
    "\n",
    "                # Process image using MediaPipe: loading image\n",
    "                image = cv2.imread(os.path.join(folder_path, filename))  # Loading the image from disk\n",
    "                # Convert the image to RGB format (MediaPipe requires RGB input)\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # Processing the image using MediaPipe Hands\n",
    "                results = hands.process(image_rgb)\n",
    "\n",
    "                # Get landmarks and add them to the label dictionary\n",
    "                if results.multi_hand_landmarks:  # Checking if hand landmarks exist in the image processing results\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        landmarks = hand_landmarks.landmark  # Retrieving the hand landmarks\n",
    "                        \n",
    "                        # Creating a dictionary containing the coordinates of the hand landmarks\n",
    "                        landmark_dict = {f'hand_landmark_{i}': {'x': landmark.x, 'y': landmark.y, 'z': landmark.z} for i, landmark in enumerate(landmarks)}\n",
    "                        image_labels['hand_landmarks'] = landmark_dict  # Adding the hand landmarks to the label dictionary for the image\n",
    "                \n",
    "               # Saving the results to a JSON file\n",
    "                with open(os.path.join(labels_folder, f'{new_file_name}.json'), 'w', encoding='utf-8') as json_file:\n",
    "                    json.dump(image_labels, json_file,  indent=4, ensure_ascii=False)\n",
    "                created += 1\n",
    "            else:\n",
    "                skipped += 1  \n",
    "    print(created, skipped)\n",
    "\n",
    "# Calling the function\n",
    "extract_labels(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_with_landmarks(labels_folder):\n",
    "    labeled_with_landmarks_count = 0\n",
    "    labeled_without_landmarks_count = 0\n",
    "    data_rows = []\n",
    "    # Iterate through files in the labels folder\n",
    "    for filename in tqdm(os.listdir(labels_folder)):\n",
    "        if filename.endswith('.json'):  # Check if the file is a JSON file\n",
    "            with open(os.path.join(labels_folder, filename), 'r', encoding='utf-8') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                # Check if the JSON file contains the 'landmarks' section\n",
    "                if 'hand_landmarks' in data:\n",
    "                    labeled_with_landmarks_count += 1\n",
    "\n",
    "                    # Inspect the structure of 'hand_landmarks'\n",
    "                    landmarks_data = data['hand_landmarks']\n",
    "                    # print(landmarks_data)  # Print or inspect the structure\n",
    "                        \n",
    "                    # Inicjalizacja wiersza dla każdego punktu charakterystycznego\n",
    "                    row = []\n",
    "                    \n",
    "                    # Dodawanie współrzędnych x, y, z każdego punktu do wiersza\n",
    "                    for landmark_key in landmarks_data:\n",
    "                        landmark = landmarks_data[landmark_key]\n",
    "                        row.extend([landmark['x'], landmark['y'], landmark['z']])\n",
    "                    \n",
    "                    # Dodanie etykiety (label) na końcu wiersza\n",
    "                    row.append(data['label'])  # Użyj label jako etykiety (label)\n",
    "                    \n",
    "                    # Dodanie wiersza do listy danych\n",
    "                    data_rows.append(row)\n",
    "\n",
    "                    # print(data_rows[0])  # Wyświetlenie pierwszego wiersza dla przykładu\n",
    "\n",
    "                else:\n",
    "                    labeled_without_landmarks_count += 1\n",
    "    print(data_rows[0])\n",
    "    print(len(data_rows[0]))\n",
    "    return labeled_with_landmarks_count, labeled_without_landmarks_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3626/3626 [00:00<00:00, 16977.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4261322021484375, 0.832544207572937, -2.4167698597921117e-07, 0.513171911239624, 0.747363805770874, -0.02008882537484169, 0.5800948143005371, 0.629132091999054, -0.03888978809118271, 0.6436914801597595, 0.5610277056694031, -0.06331326812505722, 0.7082765102386475, 0.5351800918579102, -0.09024006873369217, 0.48088496923446655, 0.4791983962059021, -0.0426514558494091, 0.494485080242157, 0.36818814277648926, -0.07652100175619125, 0.5026534795761108, 0.2925238013267517, -0.09785345941781998, 0.5090571045875549, 0.2255845069885254, -0.11323678493499756, 0.4086472988128662, 0.4774588942527771, -0.054321013391017914, 0.47094079852104187, 0.5469447374343872, -0.11051315069198608, 0.49115514755249023, 0.6556470394134521, -0.12455194443464279, 0.4916194975376129, 0.7292878031730652, -0.12253744155168533, 0.3522123098373413, 0.5256809592247009, -0.06698207557201385, 0.42579904198646545, 0.6243754625320435, -0.11562752723693848, 0.4508973956108093, 0.704166054725647, -0.11300017684698105, 0.4582262933254242, 0.7541065216064453, -0.09937997907400131, 0.30659544467926025, 0.5957543849945068, -0.08280162513256073, 0.36629900336265564, 0.6639474034309387, -0.11132006347179413, 0.4043819010257721, 0.7213658690452576, -0.10599159449338913, 0.42611798644065857, 0.7602760791778564, -0.0929282084107399, 'L']\n",
      "64\n",
      "Number of JSON files with landmarks information: 3262\n",
      "Number of JSON files without landmarks information: 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels_path= '../dataset/labels'\n",
    "number_of_labeled_files_with_landmarks, number_of_labeled_files_without_landmarks = count_files_with_landmarks(labels_path)\n",
    "print(f'Number of JSON files with landmarks information: {number_of_labeled_files_with_landmarks}')\n",
    "print(f'Number of JSON files without landmarks information: {number_of_labeled_files_without_landmarks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
