{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ant/miniconda3/envs/psl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import unicodedata\n",
    "import uuid\n",
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_folder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        shutil.rmtree(path)           # Removes all the subdirectories!\n",
    "        print('Directory existed and was cleaned')\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_raw = '../dataset/images_raw'\n",
    "folder_path = '../dataset/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory existed and was cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3741/3741 [02:08<00:00, 29.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_to_jpg(file_path, path_to_save):\n",
    "    img = Image.open(file_path)\n",
    "    if img.format == 'PNG': # Conversion of png to jpg\n",
    "        file_name = os.path.splitext(path_to_save)[0]\n",
    "        img = img.convert(\"RGB\")\n",
    "        img.save(file_name + '.jpg', 'JPEG')\n",
    "    else:\n",
    "        file_name = os.path.splitext(path_to_save)[0]\n",
    "        img.save(file_name + '.jpg', 'JPEG')\n",
    "\n",
    "create_new_folder(folder_path)\n",
    "\n",
    "for file_name in tqdm(os.listdir(folder_path_raw)):\n",
    "    if file_name.lower().endswith('.png') or  file_name.lower().endswith('.jpg'):\n",
    "        file_path = os.path.join(folder_path_raw, file_name)\n",
    "        path_to_save = os.path.join(folder_path, file_name)\n",
    "        convert_to_jpg(file_path, path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3702\n"
     ]
    }
   ],
   "source": [
    "with os.scandir(folder_path) as entries: # Used scandir instead of listdir to detect Polish characters (e.g ą,ę)\n",
    "    print(len(list(entries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory existed and was cleaned\n",
      "Directory existed and was cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "3702it [02:17, 26.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3626 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(folder_path):\n",
    "    labels = {}\n",
    "    \n",
    "    skipped = 0\n",
    "    created = 0\n",
    "    labels_folder = '../dataset/labels/'\n",
    "    images_path = '../dataset/images_renamed'\n",
    "    \n",
    "    create_new_folder(labels_folder)\n",
    "    create_new_folder(images_path)\n",
    "\n",
    "    # Initialize MediaPipe Hands\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # Searching for files in a folder\n",
    "    with os.scandir(folder_path) as entries: # Used scandir instead of listdir to detect Polish characters (e.g ą,ę)\n",
    "        for entry in tqdm(entries):\n",
    "            if entry.is_file() and entry.name.lower().endswith('.jpg'): # I want to exclude files that are not jpg\n",
    "                filename = entry.name\n",
    "                #print(filename)\n",
    "                # Extract label from the file name, ignoring dashes\n",
    "                label = ''.join([c for c in filename.split('.')[0] if not (c.isdigit() or c == '-')])\n",
    "                \n",
    "                # Skip file names starting with 'img'\n",
    "                if filename.lower().startswith('img'):\n",
    "                    # print(f'skipping starting with img {filename}')\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                \n",
    "                # Normalize the filename to ensure proper handling of diacritical marks\n",
    "                normalized_filename = unicodedata.normalize('NFC', filename)\n",
    "\n",
    "                # Check if filename contains 'sz', 'cz', 'ch' or 'rz'\n",
    "                if 'sz' in filename:\n",
    "                    labels[filename] = 'sz'\n",
    "                elif 'cz' in filename:\n",
    "                    labels[filename] = 'cz'\n",
    "                elif 'ch' in filename:\n",
    "                    labels[filename] = 'ch'\n",
    "                elif 'rz' in filename:\n",
    "                    labels[filename] = 'rz'\n",
    "                else:    \n",
    "                    # Retrieving the first letter of the file name    \n",
    "                    labels[normalized_filename] = label\n",
    "                \n",
    "                # Prepare the label dictionary for the current image\n",
    "                image_labels = {'label': label}\n",
    "                \n",
    "                new_file_name = str(uuid.uuid4()).replace('-', '')\n",
    "                shutil.copyfile(os.path.join(folder_path, filename), os.path.join(images_path, new_file_name + '.jpg'))\n",
    "\n",
    "                # Process image using MediaPipe: loading image\n",
    "                image = cv2.imread(os.path.join(folder_path, filename))  # Loading the image from disk\n",
    "                # Convert the image to RGB format (MediaPipe requires RGB input)\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # Processing the image using MediaPipe Hands\n",
    "                results = hands.process(image_rgb)\n",
    "\n",
    "                # Get landmarks and add them to the label dictionary\n",
    "                if results.multi_hand_landmarks:  # Checking if hand landmarks exist in the image processing results\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        landmarks = hand_landmarks.landmark  # Retrieving the hand landmarks\n",
    "                        \n",
    "                        # Creating a dictionary containing the coordinates of the hand landmarks\n",
    "                        landmark_dict = {f'hand_landmark_{i}': {'x': landmark.x, 'y': landmark.y, 'z': landmark.z} for i, landmark in enumerate(landmarks)}\n",
    "                        image_labels['hand_landmarks'] = landmark_dict  # Adding the hand landmarks to the label dictionary for the image\n",
    "                \n",
    "               # Saving the results to a JSON file\n",
    "                with open(os.path.join(labels_folder, f'{new_file_name}.json'), 'w', encoding='utf-8') as json_file:\n",
    "                    json.dump(image_labels, json_file,  indent=4, ensure_ascii=False)\n",
    "                created += 1\n",
    "            else:\n",
    "                skipped += 1  \n",
    "    print(created, skipped)\n",
    "\n",
    "# Calling the function\n",
    "extract_labels(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_with_landmarks(labels_folder):\n",
    "    labeled_with_landmarks_count = 0\n",
    "    labeled_without_landmarks_count = 0\n",
    "    data_rows = []\n",
    "    # Iterate through files in the labels folder\n",
    "    for filename in tqdm(os.listdir(labels_folder)):\n",
    "        if filename.endswith('.json'):  # Check if the file is a JSON file\n",
    "            with open(os.path.join(labels_folder, filename), 'r', encoding='utf-8') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                # Check if the JSON file contains the 'landmarks' section\n",
    "                if 'hand_landmarks' in data:\n",
    "                    labeled_with_landmarks_count += 1\n",
    "\n",
    "                    # Inspect the structure of 'hand_landmarks'\n",
    "                    landmarks_data = data['hand_landmarks']\n",
    "                    # print(landmarks_data)  # Print or inspect the structure\n",
    "                        \n",
    "                    # Initialisation of the line for each characteristic point\n",
    "                    row = []\n",
    "                    \n",
    "                    # Adding x, y, z coordinates of each point to the row\n",
    "                    for landmark_key in landmarks_data:\n",
    "                        landmark = landmarks_data[landmark_key]\n",
    "                        row.extend([landmark['x'], landmark['y'], landmark['z']])\n",
    "                    \n",
    "                    # Adding a label at the end of the line\n",
    "                    row.append(data['label'])  # Use the label as a label\n",
    "                    \n",
    "                    # Adding a row to the data list\n",
    "                    data_rows.append(row)\n",
    "\n",
    "                    # print(data_rows[0])  # Display of the first line for the example\n",
    "\n",
    "                else:\n",
    "                    labeled_without_landmarks_count += 1\n",
    "    print(data_rows[0])\n",
    "    print(len(data_rows[0]))\n",
    "    return labeled_with_landmarks_count, labeled_without_landmarks_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3626/3626 [00:00<00:00, 20249.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5722715258598328, 0.9279959201812744, 6.085367658670293e-07, 0.6667962670326233, 0.8835490942001343, -0.05172787234187126, 0.7500747442245483, 0.7784339189529419, -0.08351358026266098, 0.8113635182380676, 0.7292087078094482, -0.11344535648822784, 0.8760277032852173, 0.6948061585426331, -0.1403423249721527, 0.6881923675537109, 0.5869115591049194, -0.053579822182655334, 0.7228823304176331, 0.4431452751159668, -0.1276901513338089, 0.7501876950263977, 0.3440498411655426, -0.16761082410812378, 0.755721926689148, 0.2457873523235321, -0.19032491743564606, 0.6012634634971619, 0.5760300755500793, -0.06292890012264252, 0.6995595097541809, 0.5268629789352417, -0.1440703272819519, 0.7008561491966248, 0.6791463494300842, -0.14395952224731445, 0.6560532450675964, 0.7099243998527527, -0.12153636664152145, 0.5214959979057312, 0.6006360054016113, -0.08299653977155685, 0.6147222518920898, 0.5985482931137085, -0.1846313327550888, 0.6262587904930115, 0.7452564239501953, -0.16008451581001282, 0.5830004811286926, 0.7524770498275757, -0.11627408117055893, 0.4425860047340393, 0.6502628922462463, -0.10558193176984787, 0.5270194411277771, 0.6548254489898682, -0.17155258357524872, 0.5549616813659668, 0.7580951452255249, -0.14114658534526825, 0.5183264017105103, 0.780044436454773, -0.10196861624717712, 'Ł']\n",
      "64\n",
      "Number of JSON files with landmarks information: 3262\n",
      "Number of JSON files without landmarks information: 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels_path= '../dataset/labels'\n",
    "number_of_labeled_files_with_landmarks, number_of_labeled_files_without_landmarks = count_files_with_landmarks(labels_path)\n",
    "print(f'Number of JSON files with landmarks information: {number_of_labeled_files_with_landmarks}')\n",
    "print(f'Number of JSON files without landmarks information: {number_of_labeled_files_without_landmarks}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
